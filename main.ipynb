{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8b05ea",
   "metadata": {},
   "source": [
    "# Project Assignment: Short Video Recommender System (KuaiRec)\n",
    "\n",
    "Dataset Source: [Kuairec](https://kuairec.com/)\n",
    "\n",
    "Arxiv Paper: [KuaiRec: A Fully-observed Dataset and Insights for Evaluating Recommender Systems](https://arxiv.org/pdf/2202.10842)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028caae",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://nas.chongminggao.top:4430/datasets/KuaiRec.zip --no-check-certificate\n",
    "!unzip KuaiRec.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152809c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1fe6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tofeha/ING2/ING2/REMA1/FinalProject_2025_aziz.zeghal/KuaiRec 2.0/data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "# I get my dataset from a Kaggle input\n",
    "DATA_PATH = \"/kaggle/input/kuairec/KuaiRec 2.0/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   DATA_PATH = f\"{os.getcwd()}/KuaiRec/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   DATA_PATH = f\"{os.getcwd()}/KuaiRec 2.0/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   raise FileNotFoundError(\"KuaiRec dataset not found. Please check the path.\")\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7809b",
   "metadata": {},
   "source": [
    "## Step 1: Load and observe the dataset\n",
    "\n",
    "- Load and inspect the dataset\n",
    "- Handle missing or inconsistent data\n",
    "- Merge metadata for content-based models if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f60bda",
   "metadata": {},
   "source": [
    "### Small matrix\n",
    "\n",
    "This table has a density of 99.6%. This means that 99.6% of the entries in the matrix are non-zero, indicating that most users have interacted with most items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clear(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    # Date is time in a weird format\n",
    "    df.drop(\"date\", axis=\"columns\", inplace=True)\n",
    "\n",
    "    # Timestamp and time can be missing\n",
    "    # Not a problem, we want to keep the data for the density\n",
    "    df = df.astype({\n",
    "        \"user_id\": \"int32\",\n",
    "        \"video_id\": \"int32\",\n",
    "        \"play_duration\":\"int32\",\n",
    "        \"timestamp\": \"int64\",\n",
    "        \"watch_ratio\": \"float32\"}, errors=\"ignore\")\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=[\"user_id\", \"video_id\"], inplace=True)\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(f\"{DATA_PATH}/small_matrix.csv\")\n",
    "\n",
    "train_set = data_clear(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca26eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the small matrix: {train_set.shape}\")\n",
    "unique_users = train_set[\"user_id\"].nunique()\n",
    "unique_posts = train_set[\"video_id\"].nunique()\n",
    "print(f\"Matrix sparsity: {len(train_set) /(unique_posts * unique_users) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba912ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb76158",
   "metadata": {},
   "source": [
    "### Big matrix\n",
    "\n",
    "This table has a density of 16.3%. We will use this matrix for our training and testing.\n",
    "\n",
    "It contains more interactions with the same users/items of the small matrix. We do not need to substract the small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = pd.read_csv(f\"{DATA_PATH}/big_matrix.csv\")\n",
    "\n",
    "evaluation_set = data_clear(evaluation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c6994",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_categories = pd.read_csv(f\"{DATA_PATH}/kuairec_caption_category.csv\", lineterminator='\\n')\n",
    "item_categories.astype({\"video_id\": \"int32\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b262349",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "- Create meaningful features from interaction and metadata (e.g., content tags, user activity history)\n",
    "- Build user-item interaction matrix\n",
    "- Optionally extract time-based or popularity-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_score(video_id: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the popularity score of a video based on its view ratio.\n",
    "    \"\"\"\n",
    "    video_interest = train_set[train_set[\"video_id\"] == video_id]\n",
    "    return video_interest[\"watch_ratio\"].sum() / len(video_interest) if len(video_interest) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_score(148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49025c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = train_set.pivot(index='user_id', columns='video_id', values='watch_ratio').fillna(0)\n",
    "interactions = csr_matrix(matrix_train.values)\n",
    "\n",
    "# user_ids = train_set[\"user_id\"].astype(\"category\").cat.codes.values\n",
    "# item_ids = train_set[\"video_id\"].astype(\"category\").cat.codes.values\n",
    "# interactions = csr_matrix((train_set[\"watch_ratio\"], (user_ids, item_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13e82d",
   "metadata": {},
   "source": [
    "## Step 3: Model Development\n",
    "\n",
    "- Choose a recommendation approach:\n",
    "    - Collaborative filtering (e.g., ALS, Matrix Factorisation)\n",
    "    - Content-based filtering\n",
    "    - Sequence-aware models\n",
    "    - Hybrid approaches\n",
    "- Train and validate your model on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84016e",
   "metadata": {},
   "source": [
    "### Model 1: Alternating Least Squares (ALS)\n",
    "Considering that we only have implicit feedback, ALS can work well. We will not use demographic data for this simple model.\n",
    "\n",
    "This algorithm is mostly used for sparse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f59c",
   "metadata": {},
   "source": [
    "#### Pyspark imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f682a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.4.1\n",
      "Pandas version: 2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/17 20:26:16 WARN Utils: Your hostname, DESKTOP-1TVCQAV resolves to a loopback address: 127.0.1.1; using 172.17.236.101 instead (on interface eth0)\n",
      "25/04/17 20:26:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/17 20:26:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "# To evaluate the model with RMSE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# For hyperparameter tuning\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "print(f\"Spark version: {pyspark.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KuaiRec ALS\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea58e2e",
   "metadata": {},
   "source": [
    "#### Data preparation for Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9284ccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+\n",
      "|user_id|video_id|       watch_ratio|\n",
      "+-------+--------+------------------+\n",
      "|     14|     148|0.7221031811438932|\n",
      "|     14|     183| 1.907377049180328|\n",
      "|     14|    3649| 2.063310941382166|\n",
      "|     14|    5262|0.5663884673748103|\n",
      "|     14|    8234|0.4183636363636364|\n",
      "|     14|    6789|0.6487525439059321|\n",
      "|     14|    1963|0.8981230448383734|\n",
      "|     14|     175| 0.250247237390893|\n",
      "|     14|    1973|0.6178378378378379|\n",
      "|     14|     171|1.6327391221008245|\n",
      "|     14|    6803|1.3599621092516576|\n",
      "|     14|    3634|1.0625113574413956|\n",
      "|     14|    6787|2.2209484106305366|\n",
      "|     14|    1951|            2.2415|\n",
      "|     14|     179|1.4244272292731168|\n",
      "|     14|    5266|1.2312694373763076|\n",
      "|     14|    5241|0.4111530321155793|\n",
      "|     14|    6782|1.1655276381909547|\n",
      "|     14|    6788|0.7878258532652512|\n",
      "|     14|    8220|1.4898848971049878|\n",
      "+-------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+\n",
      "|user_id|video_id|       watch_ratio|\n",
      "+-------+--------+------------------+\n",
      "|      0|    3649|1.2733965215790926|\n",
      "|      0|    9598|1.2440823015294975|\n",
      "|      0|    5262|0.1076125442589782|\n",
      "|      0|    1963|0.0898852971845672|\n",
      "|      0|    8234|             0.078|\n",
      "|      0|    8228| 1.572294776119403|\n",
      "|      0|    6789|0.1753976030752996|\n",
      "|      0|    6812| 2.212061894108874|\n",
      "|      0|     183|0.1304918032786885|\n",
      "|      0|     169|1.4062659977475171|\n",
      "|      0|    1988|1.8889678703440431|\n",
      "|      0|    5274|2.0970967741935485|\n",
      "|      0|     179|2.1577385857919893|\n",
      "|      0|    3647|0.0679368262722486|\n",
      "|      0|    8248|1.2918181818181818|\n",
      "|      0|     206|0.0902172714238447|\n",
      "|      0|    6801| 1.935958459541324|\n",
      "|      0|     171| 33.27602070155262|\n",
      "|      0|    3672|1.4420652173913044|\n",
      "|      0|    2000|0.0716965742251223|\n",
      "+-------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Add the training dataframe to the Spark session\n",
    "\n",
    "# Optional: filter training data to users/items that also exist in test set\n",
    "\n",
    "# We load directly from the CSV to avoid memory issues\n",
    "# TODO: Maybe later on use parquet files for cleaned up data\n",
    "train_data = spark.read.csv(\n",
    "    f\"{DATA_PATH}/small_matrix.csv\",\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    nullValue=\"\",\n",
    "    # We have to infer for correct types\n",
    "    inferSchema=True,\n",
    ").select(\"user_id\", \"video_id\", \"watch_ratio\")\n",
    "\n",
    "train_data.show()\n",
    "\n",
    "# Load the evaluation data\n",
    "test_data = spark.read.csv(\n",
    "    f\"{DATA_PATH}/big_matrix.csv\",\n",
    "    header=True,\n",
    "    sep=\",\",\n",
    "    inferSchema=True,\n",
    "    nullValue=\"\",\n",
    ").select(\"user_id\", \"video_id\", \"watch_ratio\")\n",
    "\n",
    "\n",
    "\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40a0fb3",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fa9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS model configuration\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    rank=10,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"video_id\",\n",
    "    ratingCol=\"watch_ratio\",\n",
    "    # Handle NaN predictions\n",
    "    coldStartStrategy=\"drop\",\n",
    "    implicitPrefs=True,\n",
    ")\n",
    "\n",
    "# For CrossValidator\n",
    "params = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20]) \\\n",
    "    .addGrid(als.maxIter, [10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"watch_ratio\", predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "# CrossValidator\n",
    "cvs = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=params,\n",
    "    evaluator=evaluator,\n",
    "    # Between 2 and 5\n",
    "    numFolds=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00765697",
   "metadata": {},
   "source": [
    "#### Training\n",
    "Now with the training, we should have:\n",
    "\n",
    "R ≈ U x V\n",
    "\n",
    "Where:\n",
    "- R is the user-item interaction matrix\n",
    "- U is the user feature matrix\n",
    "- V is the item feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f41b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the ALS model on the train data\n",
    "models = cvs.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc58f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Take the best model from the CrossValidator\n",
    "my_model = models.bestModel\n",
    "\n",
    "predictions = my_model.transform(train_data)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f070cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3592511123402955\n",
      "Rank: 10\n",
      "MaxIter: 15\n",
      "RegParam: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Rank: {my_model.rank}\")\n",
    "print(f\"MaxIter: {my_model._java_obj.parent().getMaxIter()}\")\n",
    "print(f\"RegParam: {my_model._java_obj.parent().getRegParam()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac67168",
   "metadata": {},
   "source": [
    "## Step 4: Recommendation Algorithm\n",
    "\n",
    "- Predict which videos are likely to be enjoyed by each user in the test set\n",
    "- Generate a top-N ranked list of recommendations for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1f72c",
   "metadata": {},
   "source": [
    "### Model 1: Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b679d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommends = my_model.recommendForAllUsers(10)\n",
    "recommends_df = recommends.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21362f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>[(7383, 0.9606729745864868), (4040, 0.95974075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>[(7383, 0.9637352228164673), (4040, 0.96279984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>[(7383, 0.9655925035476685), (4040, 0.96465539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>[(7383, 0.9650819897651672), (4040, 0.96414554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157</td>\n",
       "      <td>[(7383, 0.9602046012878418), (4040, 0.95927274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>7135</td>\n",
       "      <td>[(7383, 0.9609105587005615), (4040, 0.95997804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>7141</td>\n",
       "      <td>[(7383, 0.9661915302276611), (4040, 0.96525388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>7142</td>\n",
       "      <td>[(7383, 0.9652813673019409), (4040, 0.96434468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>7153</td>\n",
       "      <td>[(7383, 0.9657152891159058), (4040, 0.96477800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>7162</td>\n",
       "      <td>[(7383, 0.9730678796768188), (4040, 0.97212344...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                    recommendations\n",
       "0         120  [(7383, 0.9606729745864868), (4040, 0.95974075...\n",
       "1         137  [(7383, 0.9637352228164673), (4040, 0.96279984...\n",
       "2         140  [(7383, 0.9655925035476685), (4040, 0.96465539...\n",
       "3         155  [(7383, 0.9650819897651672), (4040, 0.96414554...\n",
       "4         157  [(7383, 0.9602046012878418), (4040, 0.95927274...\n",
       "...       ...                                                ...\n",
       "1406     7135  [(7383, 0.9609105587005615), (4040, 0.95997804...\n",
       "1407     7141  [(7383, 0.9661915302276611), (4040, 0.96525388...\n",
       "1408     7142  [(7383, 0.9652813673019409), (4040, 0.96434468...\n",
       "1409     7153  [(7383, 0.9657152891159058), (4040, 0.96477800...\n",
       "1410     7162  [(7383, 0.9730678796768188), (4040, 0.97212344...\n",
       "\n",
       "[1411 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f550fd",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "- Choose suitable metrics (e.g., Precision@K, Recall@K, MAP, NDCG)\n",
    "- Evaluate performance and provide interpretations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REMA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
