{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8b05ea",
   "metadata": {},
   "source": [
    "# Project Assignment: Short Video Recommender System (KuaiRec)\n",
    "\n",
    "Dataset Source: [Kuairec](https://kuairec.com/)\n",
    "\n",
    "Arxiv Paper: [KuaiRec: A Fully-observed Dataset and Insights for Evaluating Recommender Systems](https://arxiv.org/pdf/2202.10842)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028caae",
   "metadata": {},
   "source": [
    "## Dataset import\n",
    "\n",
    "The server is down, please download from the Google Drive in the given link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87e0c3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!wget https://nas.chongminggao.top:4430/datasets/KuaiRec.zip --no-check-certificate\n",
    "!unzip KuaiRec.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152809c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf1fe6d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T19:19:44.854588Z",
     "iopub.status.idle": "2025-04-21T19:19:44.854927Z",
     "shell.execute_reply": "2025-04-21T19:19:44.854797Z",
     "shell.execute_reply.started": "2025-04-21T19:19:44.854783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tofeha/ING2/ING2/REMA1/FinalProject_2025_aziz.zeghal/KuaiRec 2.0/data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# I get my dataset from a Kaggle input\n",
    "DATA_PATH = \"/kaggle/input/kuairec/KuaiRec 2.0/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   DATA_PATH = f\"{os.getcwd()}/KuaiRec/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   DATA_PATH = f\"{os.getcwd()}/KuaiRec 2.0/data\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "   raise FileNotFoundError(\"KuaiRec dataset not found. Please check the path.\")\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7809b",
   "metadata": {},
   "source": [
    "# Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0db923c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:40:39.689176Z",
     "iopub.status.busy": "2025-04-21T17:40:39.688515Z",
     "iopub.status.idle": "2025-04-21T17:40:39.695245Z",
     "shell.execute_reply": "2025-04-21T17:40:39.694367Z",
     "shell.execute_reply.started": "2025-04-21T17:40:39.689146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def data_clear(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    # Date is time in a weird format\n",
    "\n",
    "    # Time and Date are duplicated of timestamp, we can drop them\n",
    "    df.drop(columns=[\"time\", \"date\"], inplace=True)\n",
    "    # Not a problem, we want to keep the data for the density\n",
    "    df = df.astype({\n",
    "        \"user_id\": \"int32\",\n",
    "        \"video_id\": \"int32\",\n",
    "        \"play_duration\":\"int32\",\n",
    "        \"timestamp\": \"int64\",\n",
    "        \"watch_ratio\": \"float32\"}, errors=\"ignore\")\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df[\"timestamp\"] >= 0]\n",
    "    \n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54787262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T17:40:42.037377Z",
     "iopub.status.busy": "2025-04-21T17:40:42.037002Z",
     "iopub.status.idle": "2025-04-21T17:40:42.043434Z",
     "shell.execute_reply": "2025-04-21T17:40:42.042485Z",
     "shell.execute_reply.started": "2025-04-21T17:40:42.037350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def my_describe(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Custom describe for datasets containing user_id and video_id\n",
    "    \"\"\"\n",
    "    print(f\"Shape of the small matrix: {df.shape}\")\n",
    "    unique_users = df[\"user_id\"].nunique()\n",
    "    unique_posts = df[\"video_id\"].nunique()\n",
    "    print(f\"Number of unique users: {unique_users}\")\n",
    "    print(f\"Number of unique posts: {unique_posts}\")\n",
    "    print(f\"Matrix sparsity: {len(df) /(unique_posts * unique_users) * 100}%\")\n",
    "    return df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f60bda",
   "metadata": {},
   "source": [
    "## Small matrix\n",
    "\n",
    "This table has a density of 99.6%. This means that 99.6% of the entries in the matrix are non-zero, indicating that most users have interacted with most items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0fcd8",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "small_matrix = pd.read_csv(f\"{DATA_PATH}/small_matrix.csv\")\n",
    "\n",
    "small_matrix = data_clear(small_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb76158",
   "metadata": {},
   "source": [
    "## Big matrix\n",
    "\n",
    "This table has a density of 16.3%. We will use this matrix for our training and testing.\n",
    "\n",
    "It contains more interactions with the same users/items of the small matrix. We do not need to substract the small matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0561f81d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-21T19:19:44.856262Z",
     "iopub.status.idle": "2025-04-21T19:19:44.856806Z",
     "shell.execute_reply": "2025-04-21T19:19:44.856543Z",
     "shell.execute_reply.started": "2025-04-21T19:19:44.856522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "big_matrix = pd.read_csv(f\"{DATA_PATH}/big_matrix.csv\")\n",
    "\n",
    "big_matrix = data_clear(big_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3111ab9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "big_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c6994",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d43e7b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Proportion of small_matrix relative to big_matrix: {small_matrix.shape[0] * 100 / big_matrix.shape[0]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd100212",
   "metadata": {},
   "source": [
    "## Item category encoding\n",
    "\n",
    "We have the caracteristics of the videos (author_id, video_type...) but this part requires less preprocessing.\n",
    "\n",
    "For Content-based filtering, we need to use features of the videos (list of tags). No need for TF-IDF, we will use a simple one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959d727",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# No missing values for this data\n",
    "item_categories = pd.read_csv(f\"{DATA_PATH}/item_categories.csv\")\n",
    "\n",
    "# Transform the feat column to a list (evaluate with python)\n",
    "item_categories[\"feat\"] = item_categories[\"feat\"].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7aa23b",
   "metadata": {},
   "source": [
    "## Item daily features\n",
    "\n",
    "This dataset is also interesting for content-based filtering.\n",
    "\n",
    "Mostly composed of textual data, we will use a TF-IDF vectorizer to encode the features of the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fcb010",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "item_daily_features = pd.read_csv(f\"{DATA_PATH}/item_daily_features.csv\", lineterminator='\\n')\n",
    "item_daily_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cef26",
   "metadata": {},
   "source": [
    "## Caption Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34e219",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "caption_category = pd.read_csv(f\"{DATA_PATH}/kuairec_caption_category.csv\", lineterminator='\\n')\n",
    "caption_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b262349",
   "metadata": {},
   "source": [
    "# Step 2: Feature Engineering\n",
    "\n",
    "- Create meaningful features from interaction and metadata (e.g., content tags, user activity history)\n",
    "- Build user-item interaction matrix\n",
    "- Optionally extract time-based or popularity-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e084c9",
   "metadata": {},
   "source": [
    "## Item category encoding\n",
    "\n",
    "We have the caracteristics of the videos (author_id, video_type...) but this part requires less preprocessing.\n",
    "\n",
    "For Content-based filtering, we need to use features of the videos (list of tags). No need for TF-IDF, we will use a simple one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd4b1f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use MultiLabelBinarizer to manage efficiently the feat column\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "matrix_item_category = pd.DataFrame(mlb.fit_transform(item_categories[\"feat\"]), \n",
    "                  columns=mlb.classes_,\n",
    "                  index=item_categories[\"video_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23708229",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "matrix_item_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13e82d",
   "metadata": {},
   "source": [
    "# Step 3: Two-Tower Model\n",
    "Two-Tower is an embedding model used mostly for retrieval tasks, such as search or recommendation.\n",
    "\n",
    "Two towers refer to the two separate neural networks that are used to encode the user and item features. Each tower is trained independently, and the outputs of the two towers are combined to make predictions.\n",
    "\n",
    "It is meant to be efficient for large data, and scalable to new users and items.\n",
    "\n",
    "The model is cut into 4 parts:\n",
    "- Data preparation and tuning\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Model saving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe45c3",
   "metadata": {},
   "source": [
    "## Model 1: Basic Two-Tower Model no features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea58e2e",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0f5c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:20:41.101731Z",
     "iopub.status.busy": "2025-04-21T19:20:41.100987Z",
     "iopub.status.idle": "2025-04-21T19:20:42.820777Z",
     "shell.execute_reply": "2025-04-21T19:20:42.819750Z",
     "shell.execute_reply.started": "2025-04-21T19:20:41.101698Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train, test = train_test_split(big_matrix[[\"user_id\", \"video_id\", \"watch_ratio\"]], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5ee05",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2cf8ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:21:12.003847Z",
     "iopub.status.busy": "2025-04-21T19:21:12.003505Z",
     "iopub.status.idle": "2025-04-21T19:21:12.208184Z",
     "shell.execute_reply": "2025-04-21T19:21:12.207339Z",
     "shell.execute_reply.started": "2025-04-21T19:21:12.003824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# User tower\n",
    "\n",
    "num_users = big_matrix['user_id'].nunique()\n",
    "num_videos = big_matrix['video_id'].nunique()\n",
    "\n",
    "user_input = Input(shape=(1,), name=\"user_input\")\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=50, name=\"user_embedding\")(user_input)\n",
    "user_embedding = Flatten(name=\"user_flatten\")(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33dd0fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:21:12.444927Z",
     "iopub.status.busy": "2025-04-21T19:21:12.444633Z",
     "iopub.status.idle": "2025-04-21T19:21:12.462550Z",
     "shell.execute_reply": "2025-04-21T19:21:12.461357Z",
     "shell.execute_reply.started": "2025-04-21T19:21:12.444907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Video tower\n",
    "video_input = Input(shape=(1,), name=\"video_input\")\n",
    "video_embedding = Embedding(input_dim=num_videos, output_dim=50, name=\"video_embedding\")(video_input)\n",
    "video_embedding = Flatten(name=\"video_flatten\")(video_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e5660de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:21:12.913312Z",
     "iopub.status.busy": "2025-04-21T19:21:12.912969Z",
     "iopub.status.idle": "2025-04-21T19:21:12.919524Z",
     "shell.execute_reply": "2025-04-21T19:21:12.918514Z",
     "shell.execute_reply.started": "2025-04-21T19:21:12.913291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dot product\n",
    "dot_product = Dot(axes=1)([user_embedding, video_embedding])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b5356c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:21:14.568631Z",
     "iopub.status.busy": "2025-04-21T19:21:14.568313Z",
     "iopub.status.idle": "2025-04-21T19:21:14.597400Z",
     "shell.execute_reply": "2025-04-21T19:21:14.596581Z",
     "shell.execute_reply.started": "2025-04-21T19:21:14.568609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">358,800</span> │ user_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">536,400</span> │ video_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_flatten        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_flatten       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ video_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ video_flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ user_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m358,800\u001b[0m │ user_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │    \u001b[38;5;34m536,400\u001b[0m │ video_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_flatten        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ video_flatten       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ video_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ video_flatten[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">895,200</span> (3.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m895,200\u001b[0m (3.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">895,200</span> (3.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m895,200\u001b[0m (3.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=[user_input, video_input], outputs=dot_product)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00765697",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3d38df-b06a-46ce-958b-80087b510455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T19:21:29.323904Z",
     "iopub.status.busy": "2025-04-21T19:21:29.323525Z",
     "iopub.status.idle": "2025-04-21T19:44:15.159132Z",
     "shell.execute_reply": "2025-04-21T19:44:15.157251Z",
     "shell.execute_reply.started": "2025-04-21T19:21:29.323871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745265651.627683  180690 service.cc:152] XLA service 0x7eff340055f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745265651.627721  180690 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-21 22:00:51.643094: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745265651.684036  180690 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   23/72238\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 2ms/step - loss: 2.3617   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745265651.961822  180690 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 3ms/step - loss: 2.8754 - val_loss: 2.6026\n",
      "Epoch 2/5\n",
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 3ms/step - loss: 2.6324 - val_loss: 2.6029\n",
      "Epoch 3/5\n",
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 3ms/step - loss: 2.6286 - val_loss: 2.6085\n",
      "Epoch 4/5\n",
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 3ms/step - loss: 2.5747 - val_loss: 2.6113\n",
      "Epoch 5/5\n",
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 3ms/step - loss: 2.5740 - val_loss: 2.6172\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[train[\"user_id\"], train[\"video_id\"]],\n",
    "    y=train[\"watch_ratio\"],\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    validation_data=([test[\"user_id\"], test[\"video_id\"]], test[\"watch_ratio\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2eeea",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4c4c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72238/72238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 2ms/step - loss: 2.5886\n",
      "Test loss (MSE): 2.617175817489624\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss = model.evaluate([test[\"user_id\"], test[\"video_id\"]], test[\"watch_ratio\"])\n",
    "print(f\"Test loss (MSE): {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc33e9",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0ac8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"two_tower_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac67168",
   "metadata": {},
   "source": [
    "# Step 4: Two-Tower Recommendation\n",
    "\n",
    "- Predict which videos are likely to be enjoyed by each user in the test set\n",
    "- Generate a top-N ranked list of recommendations for each user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85825f1",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f057ed1",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f550fd",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- Choose suitable metrics (e.g., Precision@K, Recall@K, MAP, NDCG)\n",
    "- Evaluate performance and provide interpretations"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7140329,
     "sourceId": 11400452,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
